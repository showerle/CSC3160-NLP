{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SLPcourse/a2-text-processing-showerle/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "In this assignment, we will focus on regular expressions and byte-pair encoding. Assignment 2 is worth 8% toward your final grade.\n",
        "\n",
        "Should you have any inquiries, please feel free to ask in the GitHub discussion forum found at: https://github.com/orgs/SLPcourse/discussions/categories/assignments.\n",
        "\n",
        "Please follow the template to finish your assignment and submit in GitHub.\n"
      ],
      "metadata": {
        "id": "f6iyutoXsYxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [50 marks] Regular expression\n",
        "\n",
        "1. [30marks] Write python code with regular expressions to clean the html webpage.\n",
        "\n",
        "  Input: https://slpcourse.github.io/materials/html_page.txt\n",
        "\n",
        "  Reference Output: https://slpcourse.github.io/materials/reference.txt\n",
        "\n",
        "2. [20 marks] Based on the output from 1, extract the lines with lecture time, tutorial time and office hours. Your need to use regular expressions.\n",
        "\n",
        "\n",
        "Note: We expect the regular expressions to be just enough for the task. If there are extra non-used regular expressions, we will deduct scores based the lines of non-used regular expressions. Each line that contains non-used regular expressions is worth 5 marks. Each uncleaned html tag is worth 2 points. Each unnecessary whitespace is worth 1 point."
      ],
      "metadata": {
        "id": "TT3nsKxz2UbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "import re \n",
        "\n",
        "def getFileByUrl(url: str, filename: str):\n",
        "  import requests\n",
        "  r = requests.get(url)\n",
        "  with open(filename, 'wb+') as f:\n",
        "      f.write(r.content)\n",
        "      return open(filename).read()\n",
        "\n",
        "#  clean the html webpage\n",
        "input = getFileByUrl('https://slpcourse.github.io/materials/html_page.txt', 'input.txt')\n",
        "text = re.sub('<[^>]+>', \"\", input)\n",
        "text = re.sub(\"(?<=\\n)\\s*?\\n|\\t\",'', text)\n",
        "text = re.sub(\"\\n \", \"\\n\", text)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "FjKVgSWFtmwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34dbcf25-33f2-4af8-8067-242794356756"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CSC3160 Fundamentals of Speech and Language Processing\n",
            "MDS6002 Natural Language Processing\n",
            "Spring 2023\n",
            "The difference between speech and language processing and other data processing is the use of knowledge\n",
            "of language. In this course, we will study how to describe, process and compute different levels of\n",
            "language knowledge including Phonetics and Phonology, Morphology, Syntax, Semantics, and how the\n",
            "language knowledge is used in speech and language applications such as named entities recognition,\n",
            "information extraction, question answering, speech recognition, and speech synthesis.\n",
            "Teaching team\n",
            "Instructor  Zhizheng Wu\n",
            "TA  Xi Chen\n",
            "TA Xueyao Zhang\n",
            "Poster Session\n",
            "A final project poster session is planned by the end of the course (tentatively May 20th 2023). This\n",
            "is to provide students the opportunities to connect with speech and language research/industry\n",
            "community.\n",
            "Anyone from the CUHK-Shenzhen and speech and language technology community are welcome to join. More\n",
            "details will be provided when it is close to the event. Feel free to reach out!\n",
            "Logistics\n",
            "Lectures: are on Tuesday/Thursday 4:00PM - 5:20PM in TB103. Note: lectures will be remote\n",
            "for the first two weeks, and hybrid afterwards. The Zoom link is posted on BB.\n",
            "Office hours \n",
            "Zhizheng Wu: Thu 2:30-3:30 PM. Daoyuan Building 321b\n",
            "Xi Chen: Wed 7-9PM. SDS Research Lab (4th Floor, Zhi Xin Building) Seat No.100\n",
            "Xueyao Zhang: Wed 7-9PM. SDS Research Lab (4th Floor, Zhi Xin Building) Seat No.78\n",
            "Contact: If you have any question, please reach out to us via email or post it to BB.\n",
            "Slack. Anyone is welcome to join the slack channel for discussion. -->\n",
            "Course Information\n",
            "This course is designed as the first course for students who are interested in speech and language\n",
            "technology. The first half of the course focuses on the fundamentals and introduces tools for\n",
            "students to use, and the second half emphasises on applications, giving students the opportunity to\n",
            "know how speech and language technology could impact human life.\n",
            "In particular, the topics include:\n",
            "Understanding human speech: spectrogram, fundamental frequency, formant, etc \n",
            "Human sounds and their organization \n",
            "Words and their relationship to other words \n",
            "Syntax: Structure of sentences \n",
            "Text processing and regular expressions \n",
            "Language models \n",
            "Embedding: Representations of the meaning of words \n",
            "Word classifications and Named entities recognition \n",
            "Applications: speech recognition, speech synthesis, machine translation, chatbot, etc\n",
            "Prerequisites\n",
            "Proficiency in LaTex:  All the reports need to be written by using LaTex. A template will be\n",
            "provided. If you are not familiar with LaTex, please learn from the tutorial in advance.\n",
            "Proficiency in GitHub:  All the source codes need to be submitted in GitHub. \n",
            "Proficiency in Python: All the assignments will be in Python (using Numpy and PyTorch). \n",
            "Basic machine learning knowledge:  It is possible to take this course without any machine\n",
            "learning knowledge, however, the course will be easier if you have foundations of machine learning.\n",
            "Basic Concepts of probability:  It will be easier for you to understand some lectures if you\n",
            "know basics of probability. \n",
            "Textbooks\n",
            "Recommended Books:\n",
            "Speech and Language Processing\n",
            "(3rd ed. draft), by Dan Jurafsky and James H. Martin\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  extract the lines with lecture time, tutorial time and office hours. \n",
        "lecture_time = re.search(\"Lectures[^\\.]+\", text)\n",
        "print(\"【lecture time】:\\n\", lecture_time.group())\n",
        "\n",
        "tutorial_time_office_hours = re.search('Office hours(\\n|.*){8}', text).group()\n",
        "print(\"【tutorial time and office hours】:\", tutorial_time_office_hours[len('Office hours'):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Kvvwp3zkTb",
        "outputId": "6c731f9c-dbdf-4755-83f7-74015582c0fa"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【lecture time】:\n",
            " Lectures: are on Tuesday/Thursday 4:00PM - 5:20PM in TB103\n",
            "【tutorial time and office hours】:  \n",
            "Zhizheng Wu: Thu 2:30-3:30 PM. Daoyuan Building 321b\n",
            "Xi Chen: Wed 7-9PM. SDS Research Lab (4th Floor, Zhi Xin Building) Seat No.100\n",
            "Xueyao Zhang: Wed 7-9PM. SDS Research Lab (4th Floor, Zhi Xin Building) Seat No.78\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [50 marks] Byte-pair encoding\n",
        "\n",
        "In Lecture 6, we talked about Byte-Pair Encoding (BPE). In this assignment, the task is to implement a byte-pair encoding algorithm to learn subword tokens.\n",
        "\n",
        "Here is a vocabulary with frequency, \n",
        "```\n",
        "5 oneumonoultramicroscopicsilicovolcanoconiosis\n",
        "4 hippopotomonstrosesquippedaliophobia\n",
        "3 supercalifragilisticexpialidocious\n",
        "2 pseudopseudohypoparathyroidism\n",
        "1 floccinaucinihilipilification\n",
        "2 antidisestablishmentarianism\n",
        "3 honorificabilitudinitatibus\n",
        "```\n",
        "The first column represents the occurency frequency, and the second column represents the words.\n",
        "\n",
        "In the implementation, k is set to be 5. "
      ],
      "metadata": {
        "id": "8TD1kIfo1emC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "from typing import List\n",
        "import re\n",
        "\n",
        "def BPE(C: List, F: List, k: int):\n",
        "  res = {}\n",
        "  V = list(set([list(s) for s in C][0]))\n",
        "  for t in range(k):\n",
        "    mfpair, mf = \"\", 0\n",
        "    for tmp, s in enumerate(C):\n",
        "      f = F[tmp]\n",
        "      for i in range(len(s)-1):\n",
        "        pair = s[i:i+2]\n",
        "        if pair == mfpair:\n",
        "          mf += f\n",
        "        else:\n",
        "          mfpair, mf = (pair, f) if f > mf else(mfpair, mf)\n",
        "    C = list(map(lambda x: x.replace(mfpair, str(t)), C))\n",
        "    for i in set(filter(None, re.findall('\\d', mfpair))):\n",
        "      mfpair = mfpair.replace(i, res[int(i)])\n",
        "    res[t] = mfpair\n",
        "    V.append(mfpair)\n",
        "\n",
        "  return V"
      ],
      "metadata": {
        "id": "_L6aAKCs2Rdz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = ['oneumonoultramicroscopicsilicovolcanoconiosis', 'hippopotomonstrosesquippedaliophobia','supercalifragilisticexpialidocious',\n",
        "'pseudopseudohypoparathyroidism','floccinaucinihilipilification','antidisestablishmentarianism','honorificabilitudinitatibus']\n",
        "frequency = [5, 4, 3, 2, 1, 2, 3]\n",
        "merge = 5\n",
        "print(BPE(text, frequency, merge))"
      ],
      "metadata": {
        "id": "NYzimXmYsG5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55940d9-bb40-4a90-f995-359b87598e96"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['o', 'v', 'a', 'e', 's', 'm', 'l', 'i', 'n', 'r', 'p', 'u', 't', 'c', 'on', 'one', 'oneu', 'oneum', 'oneumon']\n"
          ]
        }
      ]
    }
  ]
}